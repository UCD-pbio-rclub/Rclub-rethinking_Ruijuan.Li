---
title: "Chapter-13-assignment-01"
author: "Ruijuan Li"
date: "1/27/2017"
output: 
  html_document: 
    keep_md: yes
---

```{r}
# 13E1 add to the the following model varying slopes on the predictor x. 
# see attached figure 
```

```{r}
# 13E2. Think up a context in which varying intercepts will be positively correlated with varying slopes. Provide a mechanistic explanation for the correlation. 

# higher intercept with a higer slope... don't have a good example now... come back later... 
```

```{r}
# Repeat the café robot simulation from the beginning of the chapter. This time, set rho to zero, so that there is no correlation between intercepts and slopes. How does the posterior distribution of the correlation reflect this change in the underlying simulation? 

library(rethinking)
# simulate data 

a <- 3.5 # average morning wait time
b <- (-1) # average difference afternnon wait time
sigma_a <- 1 # std dev in intercepts
sigma_b <- 0.5 # std dev in slopes
rho <- 0.5 # correlation between intercepts and slopes

Mu <- c(a, b)

cov_ab <- sigma_a*sigma_b*rho
Sigma <- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2)
matrix(c(1,2,3,4), nrow = 2, ncol = 2)

N_cafes <- 20 # number of cafes 

library(MASS)
set.seed(5) # used to replicate examples
vary_effects <- mvrnorm(N_cafes, Mu, Sigma)
vary_effects

a_cafe <- vary_effects[,1]
b_cafe <- vary_effects[,2]

# simulate robot visit to cafes and collecting data 
N_visits <- 10 # number of visit 
afternoon <- rep(0:1, N_visits*N_cafes/2) # robot visit to cafes, 20 in total, 10 visit to each, 1 indicate
# in the afternoon, 0 indicate in the morning. 
length(afternoon) # 200 
cafe_id <- rep(1:N_cafes, each=N_visits) # repeat 10 times of each cafe 

mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon # generate average waiting time for each cafe? 
# what this code is doing? 
sigma <- 0.5 # std dev within cafes 
wait <- rnorm(N_visits*N_cafes, mu, sigma) # simulate wait time based using mu and sigma 
d <- data.frame(cafe=cafe_id, afternoon=afternoon, wait=wait) # make this into a dataframe
head(d)

######
a2 <- 3.5 # average morning wait time
b2 <- (-1) # average difference afternnon wait time
sigma_a2 <- 1 # std dev in intercepts
sigma_b2 <- 0.5 # std dev in slopes
rho2 <- -0.7 # correlation between intercepts and slopes

Mu2 <- c(a2, b2)

cov_ab2 <- sigma_a2*sigma_b2*rho2
Sigma2 <- matrix(c(sigma_a2^2, cov_ab2, cov_ab2, sigma_b2^2), ncol = 2)

library(MASS)
set.seed(5) # used to replicate examples
vary_effects2 <- mvrnorm(N_cafes, Mu2, Sigma2)
vary_effects2

a_cafe2 <- vary_effects2[,1]
b_cafe2 <- vary_effects2[,2]

# simulate robot visit to cafes and collecting data 
afternoon <- rep(0:1, N_visits*N_cafes/2) # robot visit to cafes, 20 in total, 10 visit to each, 1 indicate
# in the afternoon, 0 indicate in the morning. 
length(afternoon) # 200 
cafe_id <- rep(1:N_cafes, each=N_visits) # repeat 10 times of each cafe 

mu2 <- a_cafe2[cafe_id] + b_cafe2[cafe_id]*afternoon # generate average waiting time for each cafe? 
# what this code is doing? 
sigma2 <- 0.5 # std dev within cafes 
wait2 <- rnorm(N_visits*N_cafes, mu2, sigma2) # simulate wait time based using mu and sigma 
d2 <- data.frame(cafe=cafe_id, afternoon=afternoon, wait=wait2) # make this into a dataframe

head(d)
######

# model 
m13M1 <- map2stan(
  alist(
    wait ~ dnorm(mu, sigma), # likelihood
    mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon, # linear model
    c(a_cafe,b_cafe)[cafe] ~ dmvnorm2(c(a,b), sigma_cafe, Rho), # population of varying effects, don't quite
    # understand this code, where is the covariance matrix??? 
    a ~ dnorm(0, 10), 
    b ~ dnorm(0, 10), 
    sigma_cafe ~ dcauchy(0, 2), 
    sigma ~ dcauchy(0, 2), 
    Rho ~ dlkjcorr(1) # prior for covariance 
  ), 
  data = d, 
  iter = 5000, warmup = 2000, chains = 2)

# examine the posterior correlation between intercept and slopes 
precis(m13M1, depth = 2)
post <- extract.samples(m13M1)
dens(post$Rho[,1,2]) 

# why a positive correlation from the posterior? used the same code as in the book, except that I changed Rho=0, and Rho prior to 1. don't understand... 
```

```{r}
# 13M2. Fit this multilevel model to the simulated café data: Use WAIC to compare this model to the model from the chapter, the one that uses a multi-variate Gaussian prior. Explain the result. 

# simulate data, back to Rho=0.7 
a <- 3.5 # average morning wait time
b <- (-1) # average difference afternnon wait time
sigma_a <- 1 # std dev in intercepts
sigma_b <- 0.5 # std dev in slopes
rho <- 0.7 # correlation between intercepts and slopes

Mu <- c(a, b)

cov_ab <- sigma_a*sigma_b*rho
Sigma <- matrix(c(sigma_a^2, cov_ab, cov_ab, sigma_b^2), ncol = 2)
matrix(c(1,2,3,4), nrow = 2, ncol = 2)

N_cafes <- 20 # number of cafes 

library(MASS)
set.seed(5) # used to replicate examples
vary_effects <- mvrnorm(N_cafes, Mu, Sigma)
vary_effects

a_cafe <- vary_effects[,1]
b_cafe <- vary_effects[,2]

# simulate robot visit to cafes and collecting data 
N_visits <- 10 # number of visit 
afternoon <- rep(0:1, N_visits*N_cafes/2) # robot visit to cafes, 20 in total, 10 visit to each, 1 indicate
# in the afternoon, 0 indicate in the morning. 
length(afternoon) # 200 
cafe_id <- rep(1:N_cafes, each=N_visits) # repeat 10 times of each cafe 

mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon # generate average waiting time for each cafe? 
# what this code is doing? 
sigma <- 0.5 # std dev within cafes 
wait <- rnorm(N_visits*N_cafes, mu, sigma) # simulate wait time based using mu and sigma 
d <- data.frame(cafe=cafe_id, afternoon=afternoon, wait=wait) # make this into a dataframe

# model in the book 
library(rethinking)
m13.1 <- map2stan(
  alist(
    wait ~ dnorm(mu, sigma), # likelihood
    mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon, # linear model
    c(a_cafe,b_cafe)[cafe] ~ dmvnorm2(c(a,b), sigma_cafe, Rho), # population of varying effects, don't quite
    # understand this code, where is the covariance matrix??? 
    a ~ dnorm(0, 10), 
    b ~ dnorm(0, 10), 
    sigma_cafe ~ dcauchy(0, 2), 
    sigma ~ dcauchy(0, 2), 
    Rho ~ dlkjcorr(2) # prior for covariance 
  ), 
  data = d, 
  iter = 5000, warmup = 2000, chains = 2)
precis(m13.1, depth = 2)

m13M2 <- map2stan(
  alist(
    wait ~ dnorm(mu, sigma), # likelihood
    mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon, # linear model
    a_cafe[cafe] ~ dnorm(a, sigma_a),
    b_cafe[cafe] ~ dnorm(b, sigma_b),
    a ~ dnorm(0, 10), 
    b ~ dnorm(0, 10), 
    sigma_a ~ dcauchy(0, 1),
    sigma_b ~ dcauchy(0, 1), 
    sigma ~ dcauchy(0, 1) 
    ), 
  data = d, 
  iter = 5000, warmup = 2000, chains = 2) 
precis(m13M2, depth=2)

compare(m13.1, m13M2)
# the model in the book is better because it considers the correlation between intercept and slope whereas the model we constructed here does not. 
```

```{r}
# 13M3. Re-estimate the varying slopes model for the UCBadmit data, now using a non-centered parameterization. Compare the efficiency of the forms of the model, using n_eff. Which is better? Which chain sampled faster? 

library(rethinking)
data("UCBadmit")
d <- UCBadmit
d$male <- ifelse(d$applicant.gender=="male", 1,0)
d$dept_id <- coerce_index(d$dept)

# model here  
m13M3 <- map2stan(
  alist(
    admit ~ dbinom(applications, p), 
    logit(p) <- a_dept[dept_id] + 
                bm_dept[dept_id]*male, 
    c(a_dept, bm_dept)[dept_id] ~ dmvnorm2(c(a,bm), sigma_dept, Rho), 
    a ~ dnorm(0, 10), 
    bm ~ dnorm(0,1), 
    sigma_dept ~ dcauchy(0,2),
    Rho ~ dlkjcorr(2)
  ), 
  data = d)

# model in the book 
# m13.3 <- map2stan(
#   alist(
#     admit ~ dbinom(applications, p), 
#     logit(p) <- a_dept[dept_id] + 
#                 bm_dept[dept_id]*male, 
#     c(a_dept, bm_dept)[dept_id] ~ dmvnorm2(c(a,bm), sigma_dept, Rho), 
#     a ~ dnorm(0, 10), 
#     bm ~ dnorm(0,1), 
#     sigma_dept ~ dcauchy(0,2),
#     Rho ~ dlkjcorr(2)
#   ), 
#   data = d, warmup = 1000, iter = 4000, chains = 4, cores = 2)
# R studio keeps crashing, not able to get the model 

```

```{r}
# 13H1. Let's revisit the Bangladesh fertility data, data(bangladesh), from the practice problems for Chapter 12. Fit a model with both varying intercepts by district_id and varying slopes of urban by district_id. You are still predicting use.contraception. Inspect the correlation between the intercepts and slopes. Can you interpret this correlation, in terms of what it tells you about the pattern of contraceptive use in the sample? It might help to plot the mean (or median) varying effect estimates for both the intercepts and slopes, by district. Then you can visualize the correlation and maybe more easily think through what it means to have a particular correlation. Plotting predicted proportion of women using contraception, with urban women on one axis and rural on the other, might also help. 

# get data, 1934 women's fertility data 
library(rethinking)
data("bangladesh")
d.fertility <- bangladesh
head(d.fertility) # 1) district: where they are from 2) use.contraception: 0/1 indicate yes or no 3) urban: from city or rural area 
colnames(d.fertility) <- gsub("\\.", "_", colnames(d.fertility)) # remove dots 
head(d.fertility)
dim(d.fertility) # 1934    6 
str(d.fertility)

# The first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. Recall that these values will be index values inside the model. If there are gaps, you'll have parameters for which there is no data to inform them. Worse, the model probably won't run. Look at the unique values of the district variable: 

sort(unique(d.fertility$district))

# District 54 is absent. So district isn't yet a good index variable, because it's not contiguous. This is easy to fix. Just make a new variable that is contiguous. This is enough to do it: 

d.fertility$district_id <- as.integer(as.factor(d.fertility$district))
sort(unique(d.fertility$district_id))
```

```{r}
# Now, focus on predicting use.contraception, clustered by district_id. 
# create dummy variable 
# fit a multilevel model with varying intercepts for district.  
m12H1.2 <- map2stan(
  alist(
    use_contraception ~ dbinom(1, p),
    logit(p) <- a_district[district_id],
    a_district[district_id] ~ dnorm(a, sigma),
    a ~ dnorm(0, 1), 
    sigma ~ dcauchy(0, 1)  
  ), data = d.fertility, iter = 4000, chains = 4, cores = 2) 

# fit a multilevel model with varying intercepts for district and for slope too... 
m13H1 <- map2stan(
  alist(
    use_contraception ~ dbinom(1, p),
    logit(p) <- a_district[district_id] + 
                b_district[district_id]*urban,
    c(a_district, b_district)[district_id] ~ dmvnorm2(c(a, b), sigma_district, Rho),
    a ~ dnorm(0, 1),
    b ~ dnorm(0, 1), 
    sigma_district ~ dcauchy(0, 1),
    Rho ~ dlkjcorr(2)
  ), data = d.fertility, iter = 4000, chains = 4, cores = 2) 

precis(m12H1.2, depth = 2)
precis(m13H1, depth = 2)
compare(m13H1, m12H1.2) # the model with variant slope is much better... 

post <- extract.samples(m13H1)
dens(post$Rho[,1,2]) # a strong negative corrleation between intecept and slope 

# this negative correlation suggests that: in a district where it has the highest ratio of using contraception, the variation between its urban and rural area in using contraception is smaller. 

# plot the mean varying effect estimates for both the intercept and slope, by district
a <- apply(post$a_district, 2, mean) # get the mean of intercept 
b <- apply(post$b_district, 2, mean) # mean of slope 

plot(a, b, xlab="intercept", ylab="slope",
     pch=16, col=rangi2, ylim=c(min(b)-0.1, max(b)+0.1),
     xlim=c(min(a)-0.1, max(a)+0.1)) 
# negative correlation 
# plot the predicted contraception for rual and urban area seperately, how? 


```

















